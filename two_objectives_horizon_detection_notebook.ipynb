{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision-Based Horizon Detection with Dual Global and Local Objectives\n",
    "\n",
    "The following notebook walks you through an implementation of a computer vision-based horizon detection that uses a two-stage objective that greatly reduces computational overhead compared to the typical exhaustive search approach.\n",
    "\n",
    "The first objective (\"global\") attempts to find the range of combinations of \"pitch\" and \"roll\" (attitude and angle) corresponding to a halfplane that likely subdivdes the sky from the rest of the image.  The second objective (\"local\") searches exhaustively through these combinations to find the halfplane that maximizes the difference in average intensity of the two halfplanes in the immediate viscinity of the halfplane.\n",
    "\n",
    "Compared with an exhaustive search of pitch and roll combinations performed at the outset, this method obtains perfect accuracy on our datset with a full order-of-magnitute less computations.  This method benefits from the assumption that a \"sky\" as represented by image data has higher intensity values than the ground pixels (higher mean), and that the sky has higher consistency of representation (lower variance).  A \"coefficient of variance\" calculation (ratio of mean to variance) performed on the full range of angle/attitude for all images in the set suggests that--at least for our data--the optimization surface is approximately convex, allowing for confident use of subsampling in the global objective.\n",
    "\n",
    "Exhaustive search over the second objective for our dataset in the data exploration phase however reveals numerous local maxima- therefore we must employ exhaustive search over the subregion identified in the global objective in runtime.  Regardless, we observe no loss of accuracy on out output.\n",
    "\n",
    "The method is demonstrated on a selection of maritime images whose time-of-day, glare effects, and ground-truth horizon location within the frame and varied.\n",
    "\n",
    "*Main()* and associated functions are located in *two_objectives_horizon_detection.py*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import path\n",
    "import os\n",
    "\n",
    "import two_objectives_horizon_detection as tohd\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "img_dir = os.path.join(current_dir,\"images\")\n",
    "files = [os.path.join(\"images\",x) for x in os.listdir(img_dir) if x.endswith('.jpeg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOBAL OBJECTIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#GLOBAL OBJECTIVE SETTINGS\n",
    "img_file = files[10]\n",
    "global_img_reduction = 0.1\n",
    "global_angles = (-90,91,5)\n",
    "global_distances = (5,100,5) \n",
    "global_buffer_size = 3\n",
    "\n",
    "#GLOBAL OBJECTIVE MAIN ROUTINE\n",
    "global_search = tohd.main(img_file, \n",
    "                          img_reduction = global_img_reduction,\n",
    "                          angles = global_angles, \n",
    "                          distances = global_distances, \n",
    "                          buffer_size = global_buffer_size, \n",
    "                          local_objective = 0)  #2m5s\n",
    "\n",
    "#GLOBAL OBJECTIVE OPTIMIZATION SURFACE\n",
    "objective_1 = np.max((global_search[:,:,0] - global_search[:,:,1]),0) / (global_search[:,:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Objective Optimization Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.arange(0, len(range(*global_angles)), 1)\n",
    "Y = np.arange(0, len(range(*global_distances)), 1)\n",
    "X, Y = np.meshgrid(Y, X)\n",
    "Z = objective_1\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_wireframe(X,Y,Z, rstride=1, cstride=1)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOCAL OBJECTIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LOCAL OBJECTIVE SETTINGS\n",
    "above_two_sigma = (2* np.nanstd(objective_1)) + np.nanmean(objective_1)\n",
    "\n",
    "local_angles = global_search[np.where(objective_1 > above_two_sigma)[0],\n",
    "                             np.where(objective_1 > above_two_sigma)[1]][:,6]\n",
    "local_distances = global_search[np.where(objective_1 > above_two_sigma)[0],\n",
    "                                np.where(objective_1 > above_two_sigma)[1]][:,7]\n",
    "local_angle_range = (int(np.min(local_angles))-2,\n",
    "                     int(np.max(local_angles))+3,1)\n",
    "local_distance_range = (int(np.min(local_distances))-2,\n",
    "                        int(np.max(local_distances))+3,1)\n",
    "\n",
    "local_img_reduction = 0.25\n",
    "local_angles = local_angle_range\n",
    "local_distances = local_distance_range\n",
    "local_buffer_size = 5\n",
    "\n",
    "#LOCAL OBJECTIVE MAIN ROUTINE\n",
    "print(\"Evaluating\",(len(range(*local_angle_range))*len(range(*local_distance_range))),\"candidates...\")\n",
    "\n",
    "local_search = tohd.main(img_file, \n",
    "                         img_reduction = local_img_reduction,\n",
    "                         angles = local_angles, \n",
    "                         distances = local_distances, \n",
    "                         buffer_size = local_buffer_size, \n",
    "                         local_objective = 1)  #2m5s\n",
    "\n",
    "#LOCAL OBJECTIVE OPTIMIZATION SURFACE\n",
    "objective_2 =  (local_search[:,:,4] - local_search[:,:,5])**2 / local_search[:,:,2]\n",
    "\n",
    "#DETECTED HORIZON LINE\n",
    "horizon_line = local_search[np.unravel_index(objective_2.argmax(), objective_2.shape)]\n",
    "print(\"For \",img_file,\", best predicted line is\",horizon_line[6],\"degrees and a distance of\",horizon_line[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETECTED HORIZON LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVERLAY HORIZON LINE ON INPUT IMAGE AND DISPLAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(img_file,0)\n",
    "line_coordinates = tohd.get_plane_indicator_coord(img,int(horizon_line[6]),horizon_line[7]/100,0)[2:4]\n",
    "cv2.line(img,(line_coordinates[0][0],line_coordinates[0][1]),(line_coordinates[1][0],line_coordinates[1][1]),(0,0,255),2)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
